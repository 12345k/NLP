{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "# nltk.download('all')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Mary and Samantha arrived at the bus station early but waited until noon for the bus. I looked for Mary and Samantha at the bus station.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizing the text\n",
    "## sentence tokenize \n",
    "## word  tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mary and Samantha arrived at the bus station early but waited until noon for the bus.', 'I looked for Mary and Samantha at the bus station.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "sents = sent_tokenize(text)\n",
    "print(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Mary', 'and', 'Samantha', 'arrived', 'at', 'the', 'bus', 'station', 'early', 'but', 'waited', 'until', 'noon', 'for', 'the', 'bus', '.'], ['I', 'looked', 'for', 'Mary', 'and', 'Samantha', 'at', 'the', 'bus', 'station', '.']]\n"
     ]
    }
   ],
   "source": [
    "words = [word_tokenize(sent) for sent in sents]\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing the stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "customStopwords = set(stopwords.words('english')+list(punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mary', 'Samantha', 'arrived', 'bus', 'station', 'early', 'waited', 'noon', 'bus', 'I', 'looked', 'Mary', 'Samantha', 'bus', 'station']\n"
     ]
    }
   ],
   "source": [
    "# wordsWOstopwords = [words for word in word_tokenize(text) if word not in customStopwords]\n",
    "# print(wordsWOstopwords)\n",
    "wordsWOstopped=[]\n",
    "for word in word_tokenize(text):\n",
    "    if word not in customStopwords:\n",
    "        wordsWOstopped.append(word)\n",
    "print(wordsWOstopped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('I', 'looked'), 1),\n",
       " (('Mary', 'Samantha'), 2),\n",
       " (('Samantha', 'arrived'), 1),\n",
       " (('Samantha', 'bus'), 1),\n",
       " (('arrived', 'bus'), 1),\n",
       " (('bus', 'I'), 1),\n",
       " (('bus', 'station'), 2),\n",
       " (('early', 'waited'), 1),\n",
       " (('looked', 'Mary'), 1),\n",
       " (('noon', 'bus'), 1),\n",
       " (('station', 'early'), 1),\n",
       " (('waited', 'noon'), 1)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.collocations import *\n",
    "bigram_measure= nltk.collocations.BigramAssocMeasures()\n",
    "finder = BigramCollocationFinder.from_words(wordsWOstopped)\n",
    "sorted(finder.ngram_fd.items())\n",
    "# finder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['marry', 'clos', 'on', 'clos', 'night', 'when', 'she', 'was', 'mood', 'to', 'clos', '.']\n"
     ]
    }
   ],
   "source": [
    "text2 = \"Marry closed on closing night when she was mood to close.\"\n",
    "\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "\n",
    "st= LancasterStemmer()\n",
    "stemmedWords = [st.stem(word) for word in word_tokenize(text2)]\n",
    "\n",
    "\n",
    "print(stemmedWords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POS tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Marry', 'NNP'),\n",
       " ('closed', 'VBD'),\n",
       " ('on', 'IN'),\n",
       " ('closing', 'NN'),\n",
       " ('night', 'NN'),\n",
       " ('when', 'WRB'),\n",
       " ('she', 'PRP'),\n",
       " ('was', 'VBD'),\n",
       " ('mood', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('close', 'VB'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(word_tokenize(text2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disambiguating Words Meaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('bass.n.01') the lowest part of the musical range\n",
      "Synset('bass.n.02') the lowest part in polyphonic music\n",
      "Synset('bass.n.03') an adult male singer with the lowest voice\n",
      "Synset('sea_bass.n.01') the lean flesh of a saltwater fish of the family Serranidae\n",
      "Synset('freshwater_bass.n.01') any of various North American freshwater fish with lean flesh (especially of the genus Micropterus)\n",
      "Synset('bass.n.06') the lowest adult male singing voice\n",
      "Synset('bass.n.07') the member with the lowest range of a family of musical instruments\n",
      "Synset('bass.n.08') nontechnical name for any of numerous edible marine and freshwater spiny-finned fishes\n",
      "Synset('bass.s.01') having or denoting a low vocal or instrumental range\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "for ss in  wn.synsets('bass'):\n",
    "    print(ss,ss.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('freshwater_bass.n.01') any of various North American freshwater fish with lean flesh (especially of the genus Micropterus)\n"
     ]
    }
   ],
   "source": [
    "from nltk.wsd import lesk # specfic algo to detect meaning of the word from sentences\n",
    "sensel = lesk(word_tokenize(\"Sing in lower tone, along with the bass\"),'bass')\n",
    "print (sensel,sensel.definition())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('sea_bass.n.01') the lean flesh of a saltwater fish of the family Serranidae\n"
     ]
    }
   ],
   "source": [
    "sensel = lesk(word_tokenize(\"This sea bass is hard to catch\"),'bass')\n",
    "print (sensel,sensel.definition())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
